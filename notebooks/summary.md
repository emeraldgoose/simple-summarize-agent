## DoorDash DNN 모델의 온라인 vs 오프라인 성능 조사 방법 요약

DoorDash Ads ML 팀은 랭킹 모델에서 오프라인 평가와 온라인 추론 간의 성능 차이를 해결하기 위해 확장 가능한 디버깅 프레임워크를 사용했습니다. 이 프레임워크는 모델의 비즈니스 잠재력을 극대화하는 데 필수적입니다.

### 모델 개발 배경

2023년 초부터 레스토랑 검색 광고의 주요 내용은 아래 그림 1에 요약되어 있습니다. 다양한 모델 아키텍처를 평가한 후 MTML(Multi-Task Multi-Label) 모델 아키텍처를 채택했습니다.

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdGouL9pDnn3LKih2h4mmEwcZGPIlQYOxX_M3itKMtBWq56qBttGbcEVh8MggWkFAZWSan6jJolWjFi9-nAENu0UFG0gIVKhz_5T6wWWokIpa0JrPpXj-K2xZN0Y1xYbMLL9VSV?key=2JKv1fZGhwooiun5eP7Ez3ot)
_Figure 1: Restaurant Discovery Ads Ranking Deep Learning Milestones_

Multi-MTML V4(M4)의 목표는 모델 성능을 더욱 향상시키기 위해 더 많은 기능을 추가하는 것입니다. 이 마일스톤 중간에 온라인-오프라인 AUC 격차 조사를 위해 기존 기능 외에도 40개 이상의 밀집 기능을 추가했습니다.

| Feature Category    | Feature Data Type | Description                                                                                              |
| ------------------ | ---------------- | ------------------------------------------------------------------------------------------------------- |
| Existing Features   | Dense Features    | 주로 소비자 참여 기능                                                                                    |
|                     | Sequence Features | 소비자 참여 비즈니스/음식/요리 태그 시퀀스 및 컨텍스트 기능                                               |
| Newly Added Features | Dense Features    | 소비자 프로모션 관련 기능, 추가 소비자 참여 기능                                                          |

_Table 1: Model for investigation Feature details_

### 문제 식별

일반적으로 사용되는 오프라인 학습 데이터 구성 규칙을 사용하여 모델을 개발했습니다. 이 규칙에서 노출 데이터는 전날의 기능 값과 결합됩니다. 이 접근 방식은 '오늘' 모델 추론을 위해 '어제'의 기능 값을 활용하는 시나리오를 시뮬레이션합니다.

그러나 오프라인 평가에 비해 실시간 온라인 추론 중에 AUC가 4% 감소했습니다. 특히 온라인 AUC는 현재 프로덕션 모델에서 달성한 기준선보다 훨씬 낮았습니다.

### 근본 원인 파악을 위한 사고 과정

가설 기반 접근 방식으로 시작하여 각 가설을 검증하거나 무효화하기 위해 실험을 설계합니다. 초기 가설은 다음과 같습니다.

1.  **기능 생성 불일치**: 오프라인 기능 파이프라인이 온라인 환경을 모방하지 않아 실시간 예측에 불일치가 발생하는 경우.
2.  **데이터 분포 이동(개념 드리프트)**: 소비자 행동의 계절적 변화와 같이 시간이 지남에 따라 기본 데이터 분포가 변경되면 모델 일반화에 큰 영향을 미칠 수 있습니다.
3.  **모델 제공 불안정성**: 대기 시간 또는 잘못된 모델 버전과 같은 모델 제공 인프라 문제가 온라인 성능에 영향을 미칠 수 있습니다.

### 실험 설계 - 오프라인 재생

기능 불일치를 테스트하기 위해 동일한 온라인 노출 트래픽(그림자에서)과 동일한 오프라인 기능 결합 프로세스를 사용하여 평가 데이터 세트를 다시 생성합니다. 그런 다음 모델 추론을 실행하고 AUC를 평가합니다.

1.  회신 AUC가 이전 오프라인 평가의 AUC와 유사하면 오프라인에서 온라인으로의 성능 저하가 기능 불일치로 인한 것임을 확인합니다.
2.  회신 AUC가 그림자와 일치하지만 이전 오프라인 AUC보다 낮게 유지되면 개념 드리프트를 나타냅니다.

### 주요 결과 - AUC 벤치마크

| **Eval Date Range** | **Model**           | **Feature Generation**              | **Online vs Offline** | **AUC**        |
| ------------------ | ------------------ | ---------------------------------- | -------------------- | ------------- |
| One Week’s data in September   | Baseline (Prod Model) | Online Logging                      | Online              | Baseline Value |
|                     | New model           | Online Logging                      | Online Shadow       | -1.80%         |
|                     | New model           | -1d offline join new added features | Offline Replay      | +2.05%         |
| One Week’s data in June     | Baseline (Prod Model) | Online Logging                      | Offline             | +0.77%         |
|                     | New model           | -1d offline join new added features | Offline             | +2.105%        |

_Table 2: AUC Benchmarks for offline Reply_

*   모델을 처음 오프라인에서 학습했을 때 eval 세트의 AUC는 기준 값에 비해 2.1% AUC 향상되었습니다. 09/09 주에 온라인으로 섀도우되었을 때 1.8% 감소했습니다.
*   섀도우하는 동안 로깅 서비스에 명백한 중단이 발생하지 않았습니다(따라서 서비스 불안정성이라는 가설 #3을 일시적으로 배제할 수 있음).
*   섀도우 노출에 대한 학습 데이터와 동일한 기능 생성 프로세스를 사용하여 오프라인에서 평가를 재생하면 AUC가 2.05% 향상되어 2.1%에 매우 가깝습니다.
*   위의 증거는 주요 원인이 기능 불일치임을 시사합니다.

### 기능 불일치 조사

온라인 및 오프라인 기능 불일치에 대한 두 가지 잠재적 근본 원인이 있습니다.

*   **기능 노후화**: 가장 최근의 기능 값을 제공하는 동안 사용할 수 없는 경우에 발생합니다. 이는 주로 기능 파이프라인에서 최소 -1일 또는 -2일 지연이 발생하고 데이터 준비 후 몇 시간 후에 기능 업로드가 약간 지연되기 때문입니다.
*   **캐시된 잔류물**: 가장 최근의 파이프라인 실행 후 기능 값이 null이거나 더 이상 사용할 수 없는 경우에 발생합니다. 온라인 기능 저장소는 기존 키를 덮어쓰거나 이전 항목을 제거하지 않고 새 키를 추가하기만 하기 때문에 오래된 데이터가 지속될 수 있습니다.

새로 추가된 가장 중요한 기능에 대한 심층 분석을 수행하여 기능 제공 역학을 더 잘 이해합니다.

### 주요 통찰력

*   **기능 노후화** - 오프라인 기능 결합에 대한 현재 -1일 오프사이트는 매우 공격적인 선택입니다. 온라인 로깅 분석에 따르면 주어진 예측에 사용된 대부분의 기능 값은 소비자의 2-3일 이전 참여에서 가져온 것으로 나타났으며 데이터 생성에서 기능 가용성까지의 SLA가 긴 것으로 나타났습니다.
*   **캐시된 잔류물** - 기능 저장소에 있는 4일 이상 된 기능 값은 기능 저장소에 남아 있는 오래된 기록 값으로 인해 발생할 가능성이 있다고 가정합니다. 이로 인해 온라인 제공 중 누락률이 낮아지고 기능 불일치의 주요 요인이 됩니다.
*   **유비쿼터스**: 기능 노후화 및 캐시된 잔류물은 대부분의 기능에 영향을 미치지만 이러한 문제의 심각도는 기능에 따라 다릅니다.
*   **AUC 격차**: 기능 활성 날짜 오프사이트가 더 긴(1일에서 3일/4일) 시뮬레이션 데이터를 생성하여 이러한 문제의 영향을 확인하는 AUC 격차가 감소하는 것을 관찰했습니다.

### 가설 검증 및 루프 종료

위의 조사를 요약하고 가설 검증 루프를 종료하기 위해 새로운 학습 및 평가 데이터 세트를 구축하고 평가를 실행합니다. 현재 모델에서 상속된 기능의 경우 모든 학습 세트에서 실시간 제공 로깅 값을 계속 사용했습니다.

*   학습 및 평가 데이터 세트 모두에 대해 -1/2/3/4일 기능 오프셋 날짜와 결합된 노출 데이터로 4개의 데이터 세트를 다시 빌드하고 각각 4개의 모델을 학습합니다.
*   2개의 데이터 세트에서 4개의 모델 성능을 평가합니다(날짜 범위는 데이터 세트 간에 다름).
    *   오프라인 평가 데이터 세트 - 학습과 동일한 기능 오프셋 날짜가 있는 eval 데이터 세트입니다.
*   Shadow Log 데이터 세트 - 모든 기능 값은 온라인 실시간 모델 제공에서 로깅된 값입니다.

![](https://careersatdoordash.com/wp-content/uploads/2024/12/image-1024x565.png)

위의 그림 4에서 오프라인 AUC 대 기능 오프셋 날짜(예: 지연)를 추적하면 기능 새로 고침이 감소함에 따라 모델 성능이 저하되어 최적의 모델 정확도를 유지하는 데 적시 기능 업데이트가 중요하다는 것을 알 수 있습니다.

가장 큰 AUC 감소는 1일 지연에서 2일로 발생합니다. 온라인 대신 오프라인 AUC를 벤치마크로 선택한 이유는 기능 불일치의 영향을 배제하기 위한 것입니다.

### 제안된 솔루션

*   **단기**: 다양한 기능 오프셋(예: -2일, -3일, -4일)을 사용하여 평가 세트를 생성하고 프로덕션 AUC에 가장 가까운 오프셋을 선택합니다. 이 오프셋을 사용하여 학습 데이터를 만들고 모델을 빌드합니다.
*   **장기**: 새로운 기능에 대한 온라인 로깅을 활성화합니다. 그러나 개발 속도와 데이터 정확도 간에는 명확한 절충점이 있으며 프로젝트 계획 단계에서 신중하게 고려해야 합니다.

| Solution    | Pros                                                                  | Cons                                                                                                                                                                                                                         |
| ---------- | -------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Short-term  | AUC 불일치를 즉시 줄입니다.                                          | 캐시된 잔류물을 해결하지 않습니다.                                                                                                                                                                                           |
| Long-term   | 캐시된 잔류물과 기능 노후화를 효과적으로 해결합니다. 모델 일반화를 개선합니다. | 더 큰 트래픽의 기능 로깅을 지원하려면 개발 속도와 데이터 정확도 간의 절충점이 있고 시스템 안정성 개선이 필요합니다.                                                                                                                                                             |

_Table 5: Comparison between short-term and long-term solutions_

### 실험 결과 및 결론

블로그에서 제안된 단기 솔루션을 채택하여 최신 레스토랑 검색 광고 랭킹 모델 딥 러닝 반복에 대한 온라인 오프라인 AUC 격차를 4.3%에서 0.76%로 줄였습니다. 다른 기능 개선과 결합하여 이 반복은 올해 광고 랭킹 모델 반복 중 가장 큰 비즈니스 이익을 달성했습니다.

이 조사는 즉각적인 성능 격차를 해결했을 뿐만 아니라 실시간 시스템에서 기능 정렬의 중요성을 강조했습니다. 여기서 개발된 방법론은 다른 도메인에서 유사한 문제를 해결하기 위한 청사진 역할을 할 수 있습니다. 앞으로 견고한 로깅 시스템을 채택하고 기능 파이프라인을 확장하면 모델이 계속해서 영향력 있는 비즈니스 결과를 도출할 수 있습니다.
